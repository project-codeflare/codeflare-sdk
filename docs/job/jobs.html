<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>codeflare_sdk.job.jobs API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>codeflare_sdk.job.jobs</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># Copyright 2023 IBM, Red Hat
#
# Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import abc
from typing import TYPE_CHECKING, Optional, Dict, List
from pathlib import Path

from torchx.components.dist import ddp
from torchx.runner import get_runner
from torchx.specs import AppHandle, parse_app_handle, AppDryRunInfo

if TYPE_CHECKING:
    from ..cluster.cluster import Cluster
from ..cluster.cluster import get_current_namespace

all_jobs: List[&#34;Job&#34;] = []
torchx_runner = get_runner()


class JobDefinition(metaclass=abc.ABCMeta):
    def _dry_run(self, cluster: &#34;Cluster&#34;):
        pass

    def submit(self, cluster: &#34;Cluster&#34;):
        pass


class Job(metaclass=abc.ABCMeta):
    def status(self):
        pass

    def logs(self):
        pass


class DDPJobDefinition(JobDefinition):
    def __init__(
        self,
        script: Optional[str] = None,
        m: Optional[str] = None,
        script_args: Optional[List[str]] = None,
        name: Optional[str] = None,
        cpu: Optional[int] = None,
        gpu: Optional[int] = None,
        memMB: Optional[int] = None,
        h: Optional[str] = None,
        j: Optional[str] = None,
        env: Optional[Dict[str, str]] = None,
        max_retries: int = 0,
        mounts: Optional[List[str]] = None,
        rdzv_port: int = 29500,
        rdzv_backend: str = None,
        scheduler_args: Optional[Dict[str, str]] = None,
        image: Optional[str] = None,
        workspace: Optional[str] = f&#34;file://{Path.cwd()}&#34;,
    ):
        if bool(script) == bool(m):  # logical XOR
            raise ValueError(
                &#34;Exactly one of the following arguments must be defined: [script, m].&#34;
            )
        self.script = script
        self.m = m
        self.script_args: List[str] = script_args if script_args is not None else []
        self.name = name
        self.cpu = cpu
        self.gpu = gpu
        self.memMB = memMB
        self.h = h
        self.j = j
        self.env: Dict[str, str] = env if env is not None else dict()
        self.max_retries = max_retries
        self.mounts: List[str] = mounts if mounts is not None else []
        self.rdzv_port = rdzv_port
        self.rdzv_backend = rdzv_backend
        self.scheduler_args: Dict[str, str] = (
            scheduler_args if scheduler_args is not None else dict()
        )
        self.image = image
        self.workspace = workspace

    def _dry_run(self, cluster: &#34;Cluster&#34;):
        j = f&#34;{cluster.config.num_workers}x{max(cluster.config.num_gpus, 1)}&#34;  # # of proc. = # of gpus
        return torchx_runner.dryrun(
            app=ddp(
                *self.script_args,
                script=self.script,
                m=self.m,
                name=self.name,
                h=self.h,
                cpu=self.cpu if self.cpu is not None else cluster.config.max_cpus,
                gpu=self.gpu if self.gpu is not None else cluster.config.num_gpus,
                memMB=self.memMB
                if self.memMB is not None
                else cluster.config.max_memory * 1024,
                j=self.j if self.j is not None else j,
                env=self.env,
                max_retries=self.max_retries,
                rdzv_port=self.rdzv_port,
                rdzv_backend=self.rdzv_backend
                if self.rdzv_backend is not None
                else &#34;static&#34;,
                mounts=self.mounts,
            ),
            scheduler=cluster.torchx_scheduler,
            cfg=cluster.torchx_config(**self.scheduler_args),
            workspace=self.workspace,
        )

    def _missing_spec(self, spec: str):
        raise ValueError(f&#34;Job definition missing arg: {spec}&#34;)

    def _dry_run_no_cluster(self):
        if self.scheduler_args is not None:
            if self.scheduler_args.get(&#34;namespace&#34;) is None:
                self.scheduler_args[&#34;namespace&#34;] = get_current_namespace()
        return torchx_runner.dryrun(
            app=ddp(
                *self.script_args,
                script=self.script,
                m=self.m,
                name=self.name if self.name is not None else self._missing_spec(&#34;name&#34;),
                h=self.h,
                cpu=self.cpu
                if self.cpu is not None
                else self._missing_spec(&#34;cpu (# cpus per worker)&#34;),
                gpu=self.gpu
                if self.gpu is not None
                else self._missing_spec(&#34;gpu (# gpus per worker)&#34;),
                memMB=self.memMB
                if self.memMB is not None
                else self._missing_spec(&#34;memMB (memory in MB)&#34;),
                j=self.j
                if self.j is not None
                else self._missing_spec(
                    &#34;j (`workers`x`procs`)&#34;
                ),  # # of proc. = # of gpus,
                env=self.env,  # should this still exist?
                max_retries=self.max_retries,
                rdzv_port=self.rdzv_port,  # should this still exist?
                rdzv_backend=self.rdzv_backend
                if self.rdzv_backend is not None
                else &#34;c10d&#34;,
                mounts=self.mounts,
                image=self.image
                if self.image is not None
                else self._missing_spec(&#34;image&#34;),
            ),
            scheduler=&#34;kubernetes_mcad&#34;,
            cfg=self.scheduler_args,
            workspace=&#34;&#34;,
        )

    def submit(self, cluster: &#34;Cluster&#34; = None) -&gt; &#34;Job&#34;:
        return DDPJob(self, cluster)


class DDPJob(Job):
    def __init__(self, job_definition: &#34;DDPJobDefinition&#34;, cluster: &#34;Cluster&#34; = None):
        self.job_definition = job_definition
        self.cluster = cluster
        if self.cluster:
            self._app_handle = torchx_runner.schedule(job_definition._dry_run(cluster))
        else:
            self._app_handle = torchx_runner.schedule(
                job_definition._dry_run_no_cluster()
            )
        all_jobs.append(self)

    def status(self) -&gt; str:
        return torchx_runner.status(self._app_handle)

    def logs(self) -&gt; str:
        return &#34;&#34;.join(torchx_runner.log_lines(self._app_handle, None))

    def cancel(self):
        torchx_runner.cancel(self._app_handle)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="codeflare_sdk.job.jobs.DDPJob"><code class="flex name class">
<span>class <span class="ident">DDPJob</span></span>
<span>(</span><span>job_definition: <a title="codeflare_sdk.job.jobs.DDPJobDefinition" href="#codeflare_sdk.job.jobs.DDPJobDefinition">DDPJobDefinition</a>, cluster: Cluster = None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DDPJob(Job):
    def __init__(self, job_definition: &#34;DDPJobDefinition&#34;, cluster: &#34;Cluster&#34; = None):
        self.job_definition = job_definition
        self.cluster = cluster
        if self.cluster:
            self._app_handle = torchx_runner.schedule(job_definition._dry_run(cluster))
        else:
            self._app_handle = torchx_runner.schedule(
                job_definition._dry_run_no_cluster()
            )
        all_jobs.append(self)

    def status(self) -&gt; str:
        return torchx_runner.status(self._app_handle)

    def logs(self) -&gt; str:
        return &#34;&#34;.join(torchx_runner.log_lines(self._app_handle, None))

    def cancel(self):
        torchx_runner.cancel(self._app_handle)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="codeflare_sdk.job.jobs.Job" href="#codeflare_sdk.job.jobs.Job">Job</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="codeflare_sdk.job.jobs.DDPJob.cancel"><code class="name flex">
<span>def <span class="ident">cancel</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cancel(self):
    torchx_runner.cancel(self._app_handle)</code></pre>
</details>
</dd>
<dt id="codeflare_sdk.job.jobs.DDPJob.logs"><code class="name flex">
<span>def <span class="ident">logs</span></span>(<span>self) ‑> str</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def logs(self) -&gt; str:
    return &#34;&#34;.join(torchx_runner.log_lines(self._app_handle, None))</code></pre>
</details>
</dd>
<dt id="codeflare_sdk.job.jobs.DDPJob.status"><code class="name flex">
<span>def <span class="ident">status</span></span>(<span>self) ‑> str</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def status(self) -&gt; str:
    return torchx_runner.status(self._app_handle)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="codeflare_sdk.job.jobs.DDPJobDefinition"><code class="flex name class">
<span>class <span class="ident">DDPJobDefinition</span></span>
<span>(</span><span>script: Optional[str] = None, m: Optional[str] = None, script_args: Optional[List[str]] = None, name: Optional[str] = None, cpu: Optional[int] = None, gpu: Optional[int] = None, memMB: Optional[int] = None, h: Optional[str] = None, j: Optional[str] = None, env: Optional[Dict[str, str]] = None, max_retries: int = 0, mounts: Optional[List[str]] = None, rdzv_port: int = 29500, rdzv_backend: str = None, scheduler_args: Optional[Dict[str, str]] = None, image: Optional[str] = None, workspace: Optional[str] = 'file:///home/runner/work/codeflare-sdk/codeflare-sdk')</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DDPJobDefinition(JobDefinition):
    def __init__(
        self,
        script: Optional[str] = None,
        m: Optional[str] = None,
        script_args: Optional[List[str]] = None,
        name: Optional[str] = None,
        cpu: Optional[int] = None,
        gpu: Optional[int] = None,
        memMB: Optional[int] = None,
        h: Optional[str] = None,
        j: Optional[str] = None,
        env: Optional[Dict[str, str]] = None,
        max_retries: int = 0,
        mounts: Optional[List[str]] = None,
        rdzv_port: int = 29500,
        rdzv_backend: str = None,
        scheduler_args: Optional[Dict[str, str]] = None,
        image: Optional[str] = None,
        workspace: Optional[str] = f&#34;file://{Path.cwd()}&#34;,
    ):
        if bool(script) == bool(m):  # logical XOR
            raise ValueError(
                &#34;Exactly one of the following arguments must be defined: [script, m].&#34;
            )
        self.script = script
        self.m = m
        self.script_args: List[str] = script_args if script_args is not None else []
        self.name = name
        self.cpu = cpu
        self.gpu = gpu
        self.memMB = memMB
        self.h = h
        self.j = j
        self.env: Dict[str, str] = env if env is not None else dict()
        self.max_retries = max_retries
        self.mounts: List[str] = mounts if mounts is not None else []
        self.rdzv_port = rdzv_port
        self.rdzv_backend = rdzv_backend
        self.scheduler_args: Dict[str, str] = (
            scheduler_args if scheduler_args is not None else dict()
        )
        self.image = image
        self.workspace = workspace

    def _dry_run(self, cluster: &#34;Cluster&#34;):
        j = f&#34;{cluster.config.num_workers}x{max(cluster.config.num_gpus, 1)}&#34;  # # of proc. = # of gpus
        return torchx_runner.dryrun(
            app=ddp(
                *self.script_args,
                script=self.script,
                m=self.m,
                name=self.name,
                h=self.h,
                cpu=self.cpu if self.cpu is not None else cluster.config.max_cpus,
                gpu=self.gpu if self.gpu is not None else cluster.config.num_gpus,
                memMB=self.memMB
                if self.memMB is not None
                else cluster.config.max_memory * 1024,
                j=self.j if self.j is not None else j,
                env=self.env,
                max_retries=self.max_retries,
                rdzv_port=self.rdzv_port,
                rdzv_backend=self.rdzv_backend
                if self.rdzv_backend is not None
                else &#34;static&#34;,
                mounts=self.mounts,
            ),
            scheduler=cluster.torchx_scheduler,
            cfg=cluster.torchx_config(**self.scheduler_args),
            workspace=self.workspace,
        )

    def _missing_spec(self, spec: str):
        raise ValueError(f&#34;Job definition missing arg: {spec}&#34;)

    def _dry_run_no_cluster(self):
        if self.scheduler_args is not None:
            if self.scheduler_args.get(&#34;namespace&#34;) is None:
                self.scheduler_args[&#34;namespace&#34;] = get_current_namespace()
        return torchx_runner.dryrun(
            app=ddp(
                *self.script_args,
                script=self.script,
                m=self.m,
                name=self.name if self.name is not None else self._missing_spec(&#34;name&#34;),
                h=self.h,
                cpu=self.cpu
                if self.cpu is not None
                else self._missing_spec(&#34;cpu (# cpus per worker)&#34;),
                gpu=self.gpu
                if self.gpu is not None
                else self._missing_spec(&#34;gpu (# gpus per worker)&#34;),
                memMB=self.memMB
                if self.memMB is not None
                else self._missing_spec(&#34;memMB (memory in MB)&#34;),
                j=self.j
                if self.j is not None
                else self._missing_spec(
                    &#34;j (`workers`x`procs`)&#34;
                ),  # # of proc. = # of gpus,
                env=self.env,  # should this still exist?
                max_retries=self.max_retries,
                rdzv_port=self.rdzv_port,  # should this still exist?
                rdzv_backend=self.rdzv_backend
                if self.rdzv_backend is not None
                else &#34;c10d&#34;,
                mounts=self.mounts,
                image=self.image
                if self.image is not None
                else self._missing_spec(&#34;image&#34;),
            ),
            scheduler=&#34;kubernetes_mcad&#34;,
            cfg=self.scheduler_args,
            workspace=&#34;&#34;,
        )

    def submit(self, cluster: &#34;Cluster&#34; = None) -&gt; &#34;Job&#34;:
        return DDPJob(self, cluster)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="codeflare_sdk.job.jobs.JobDefinition" href="#codeflare_sdk.job.jobs.JobDefinition">JobDefinition</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="codeflare_sdk.job.jobs.DDPJobDefinition.submit"><code class="name flex">
<span>def <span class="ident">submit</span></span>(<span>self, cluster: Cluster = None) ‑> <a title="codeflare_sdk.job.jobs.Job" href="#codeflare_sdk.job.jobs.Job">Job</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def submit(self, cluster: &#34;Cluster&#34; = None) -&gt; &#34;Job&#34;:
    return DDPJob(self, cluster)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="codeflare_sdk.job.jobs.Job"><code class="flex name class">
<span>class <span class="ident">Job</span></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Job(metaclass=abc.ABCMeta):
    def status(self):
        pass

    def logs(self):
        pass</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="codeflare_sdk.job.jobs.DDPJob" href="#codeflare_sdk.job.jobs.DDPJob">DDPJob</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="codeflare_sdk.job.jobs.Job.logs"><code class="name flex">
<span>def <span class="ident">logs</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def logs(self):
    pass</code></pre>
</details>
</dd>
<dt id="codeflare_sdk.job.jobs.Job.status"><code class="name flex">
<span>def <span class="ident">status</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def status(self):
    pass</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="codeflare_sdk.job.jobs.JobDefinition"><code class="flex name class">
<span>class <span class="ident">JobDefinition</span></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class JobDefinition(metaclass=abc.ABCMeta):
    def _dry_run(self, cluster: &#34;Cluster&#34;):
        pass

    def submit(self, cluster: &#34;Cluster&#34;):
        pass</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="codeflare_sdk.job.jobs.DDPJobDefinition" href="#codeflare_sdk.job.jobs.DDPJobDefinition">DDPJobDefinition</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="codeflare_sdk.job.jobs.JobDefinition.submit"><code class="name flex">
<span>def <span class="ident">submit</span></span>(<span>self, cluster: Cluster)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def submit(self, cluster: &#34;Cluster&#34;):
    pass</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="codeflare_sdk.job" href="index.html">codeflare_sdk.job</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="codeflare_sdk.job.jobs.DDPJob" href="#codeflare_sdk.job.jobs.DDPJob">DDPJob</a></code></h4>
<ul class="">
<li><code><a title="codeflare_sdk.job.jobs.DDPJob.cancel" href="#codeflare_sdk.job.jobs.DDPJob.cancel">cancel</a></code></li>
<li><code><a title="codeflare_sdk.job.jobs.DDPJob.logs" href="#codeflare_sdk.job.jobs.DDPJob.logs">logs</a></code></li>
<li><code><a title="codeflare_sdk.job.jobs.DDPJob.status" href="#codeflare_sdk.job.jobs.DDPJob.status">status</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="codeflare_sdk.job.jobs.DDPJobDefinition" href="#codeflare_sdk.job.jobs.DDPJobDefinition">DDPJobDefinition</a></code></h4>
<ul class="">
<li><code><a title="codeflare_sdk.job.jobs.DDPJobDefinition.submit" href="#codeflare_sdk.job.jobs.DDPJobDefinition.submit">submit</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="codeflare_sdk.job.jobs.Job" href="#codeflare_sdk.job.jobs.Job">Job</a></code></h4>
<ul class="">
<li><code><a title="codeflare_sdk.job.jobs.Job.logs" href="#codeflare_sdk.job.jobs.Job.logs">logs</a></code></li>
<li><code><a title="codeflare_sdk.job.jobs.Job.status" href="#codeflare_sdk.job.jobs.Job.status">status</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="codeflare_sdk.job.jobs.JobDefinition" href="#codeflare_sdk.job.jobs.JobDefinition">JobDefinition</a></code></h4>
<ul class="">
<li><code><a title="codeflare_sdk.job.jobs.JobDefinition.submit" href="#codeflare_sdk.job.jobs.JobDefinition.submit">submit</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>
